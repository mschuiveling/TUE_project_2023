{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This code load the annotations, the output direction for the saved images and the name of the test set from which the images are visualized\n",
    "    # TUE Project 2023 - Visualize Inference Results\n",
    "\n",
    "    This Jupyter Notebook is used to visualize the inference results of a Detectron2 model on a test set of images. The notebook assumes that the model has already been trained and the inference results have been saved to a JSON file.\n",
    "\n",
    "    The notebook contains the following cells:\n",
    "\n",
    "    - **Cell 0:** This markdown cell that describes the purpose and contents of the notebook.\n",
    "    - **Cell 1:** Imports the necessary libraries and loads the annotations and test set information.\n",
    "    - **Cell 2:** Visualizes random images from the test set with ground truth annotations.\n",
    "    - **Cell 3:** Visualizes the predictions and saves the images to the output directory.\n",
    "    - **Cell 4:** Creates dictionaries for visualizing false positives, false negatives, and class false positives.\n",
    "    - **Cell 5:** Computes the IoU between each ground truth box and predicted boxes and creates dictionaries for true positives, false positives, false negatives, and class false positives.\n",
    "    - **Cell 6:** Saves the visualizations of false positives, false negatives, and class false positives to the output directory.\n",
    "\n",
    "    To use this notebook, make sure that the necessary libraries are installed and that the paths to the annotations, test set, and output directory are correct. Then, run each cell in order to visualize the inference results and create the necessary dictionaries for further analysis.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "import json\n",
    "import os\n",
    "\n",
    "annotation_path = \"/mnt/d/TIL_Melanoma_train_database/cell_segmentation/open_source_dataset_tiles_final/til_melanoma.json\" # path to annotation file from 01_coco_creator_5fold\n",
    "with open(annotation_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    images = data['images']\n",
    "\n",
    "# Directory where the original annotation resides\n",
    "annotation_dir = os.path.dirname(annotation_path)\n",
    "\n",
    "# Predefined folder to save the visualized images\n",
    "output_dir = '/mnt/d/TIL_Melanoma_train_database/cell_segmentation/detectron2_inference'\n",
    "\n",
    "# Load the predictions\n",
    "predictions_file = '/home/mschuive/detectron2/output/inference/coco_instances_results.json'\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_set_name = 'temp_val_annotations_stratified_fold_4'\n",
    "test_set_name_json = test_set_name + '.json'\n",
    "if test_set_name in DatasetCatalog.list():\n",
    "    DatasetCatalog.remove(test_set_name)\n",
    "register_coco_instances(str(test_set_name), {}, os.path.join(annotation_dir, (test_set_name_json)), \"/mnt/d/TIL_Melanoma_train_database/cell_segmentation/tiles_1024_TIL_dataset_paper/redone/\")\n",
    "\n",
    "\n",
    "# Get dataset dictionaries\n",
    "dataset_dicts = DatasetCatalog.get(test_set_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Visualize random images from test set with ground truth, images are not saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset dictionaries\n",
    "dataset_dicts = DatasetCatalog.get(test_set_name)\n",
    "\n",
    "# Visualize some samples\n",
    "for d in random.sample(dataset_dicts, 5):  # Adjust the number to display as needed\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(test_set_name), scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    # plt.figure(figsize=(10,10))\n",
    "    # plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    # plt.title(d[\"file_name\"])\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Visualize predictions and save the images \n",
    "    NB update the predictions file localization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "with open(predictions_file, 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "from detectron2.structures import BoxMode, Instances\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_on_image(image, predictions_for_image):\n",
    "    \"\"\"\n",
    "    Visualizes predictions on the image.\n",
    "    \n",
    "    Args:\n",
    "    - image (np.ndarray): Image on which to visualize the predictions.\n",
    "    - predictions_for_image (list[dict]): List of predictions for the image.\n",
    "    \n",
    "    Returns:\n",
    "    - visualized_image (np.ndarray): Image with visualized predictions.\n",
    "    \"\"\"\n",
    "    # Convert the predictions in Detectron2's Instances format\n",
    "    instances = Instances(image_size=image.shape[:2])\n",
    "    bbox_list = [pred[\"bbox\"] for pred in predictions_for_image]\n",
    "    bbox_list_xyxy_abs = []\n",
    "    for bbox in bbox_list:\n",
    "        bbox = BoxMode.convert(bbox, from_mode=BoxMode.XYWH_ABS, to_mode=BoxMode.XYXY_ABS)\n",
    "        bbox_list_xyxy_abs.append(bbox)\n",
    "    instances.pred_boxes = bbox_list_xyxy_abs\n",
    "    cat_list_new = []\n",
    "    cat_list = [pred[\"category_id\"] for pred in predictions_for_image]\n",
    "    for cat in cat_list:\n",
    "        if cat == 1:\n",
    "            cat = 0\n",
    "        elif cat == 2:\n",
    "            cat = 1\n",
    "        else:\n",
    "            cat = 2\n",
    "        cat_list_new.append(cat)\n",
    "    cat_tensor = torch.tensor(cat_list_new)\n",
    "    instances.pred_classes = cat_tensor\n",
    "    instances.scores = [pred[\"score\"] for pred in predictions_for_image]\n",
    "    instances.pred_masks_rle = [pred[\"segmentation\"][\"counts\"]for pred in predictions_for_image]\n",
    "    \n",
    "    visualizer = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(test_set_name).set(thing_classes=['immune_cell', 'tumor', 'other']), scale=1.2)\n",
    "    vis = visualizer.draw_instance_predictions(predictions=instances)\n",
    "    return vis.get_image()[:, :, ::-1]\n",
    "\n",
    "# Get unique image_ids from the predictions\n",
    "image_ids = list(set([pred[\"image_id\"] for pred in predictions]))\n",
    "\n",
    "# For each unique image_id, visualize the predictions\n",
    "for image_id in image_ids:\n",
    "    # Get the image\n",
    "    image_dict = next(item for item in dataset_dicts if item[\"image_id\"] == image_id)\n",
    "    if image_dict is None:\n",
    "        print(f\"No item found for image_id {image_id}\")\n",
    "        continue  # Skip this iteration and continue with the next image_id\n",
    "    image = cv2.imread(image_dict[\"file_name\"])\n",
    "    \n",
    "    # Extract predictions for this image_id\n",
    "    predictions_for_image = [pred for pred in predictions if pred[\"image_id\"] == image_id]\n",
    "    \n",
    "    # Visualize the predictions on the image\n",
    "    visualized_image = visualize_predictions_on_image(image, predictions_for_image)\n",
    "    \n",
    "    # Save the image with highlighted false negatives to the output directory\n",
    "    output_path = os.path.join(output_dir, f\"predictions{image_id}.png\")\n",
    "    cv2.imwrite(output_path, visualized_image)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(visualized_image[:, :, ::-1])\n",
    "    plt.title(f\"Predictions for Image {image_id}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Code which creates dictionary's for visualizing false positive, false negative and class false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import pairwise_iou\n",
    "from detectron2.structures import Boxes, BoxMode\n",
    "import json\n",
    "import torch\n",
    "\n",
    "\n",
    "with open(predictions_file, 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "# Get unique image_ids from the predictions\n",
    "image_ids = list(set([pred[\"image_id\"] for pred in predictions]))\n",
    "\n",
    "\n",
    "class_id_to_label = {\n",
    "    0: [\"immune_cell\", (0, 0, 255)], # blue for immune cell \n",
    "    1: [\"tumor\", (255,0 ,0)] , # red for tumor\n",
    "    2: [\"other\", (0, 255, 0)], # green for other\n",
    "    'none' : [\"none\", (0, 0, 0)]\n",
    "}\n",
    "\n",
    "class_false_negative = []\n",
    "# IoU threshold to determine if a prediction matches a ground truth\n",
    "upper_threshold = 0.4  # Example value for upper threshold\n",
    "lower_threshold = 0.0  # Example value for lower threshold\n",
    "\n",
    "true_positive = []\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "class_false_positive = []\n",
    "\n",
    "# For each unique image_id, visualize the predictions\n",
    "for image_id in image_ids:\n",
    "\n",
    "    # Get the image\n",
    "    gt_image_dict = next(item for item in dataset_dicts if item[\"image_id\"] == image_id)\n",
    "    image = cv2.imread(gt_image_dict[\"file_name\"])\n",
    "\n",
    "    # Extract predictions for this image_id\n",
    "    predictions_for_image = [pred for pred in predictions if pred[\"image_id\"] == image_id]\n",
    "    for entry in predictions_for_image:\n",
    "        # Define a mapping dictionary\n",
    "        category_id_mapping = {1: 0, 2: 1, 3: 2}\n",
    "        entry['category_id'] = category_id_mapping[entry['category_id']]\n",
    "        bbox_xyxy = BoxMode.convert(entry['bbox'], from_mode=BoxMode.XYWH_ABS, to_mode=BoxMode.XYXY_ABS)\n",
    "        entry['bbox_abs'] = bbox_xyxy\n",
    "        # Extract the bbox_abs values and add their sum to total_sum\n",
    "\n",
    "  \n",
    "\n",
    "    # Extract ground truth bounding boxes and classes for this image_id\n",
    "    ground_truth_for_image = gt_image_dict[\"annotations\"]\n",
    "    for entry in ground_truth_for_image:\n",
    "        entry['category_id'] = entry['category_id']\n",
    "        bbox_xyxy = BoxMode.convert(entry['bbox'], from_mode=BoxMode.XYWH_ABS, to_mode=BoxMode.XYXY_ABS)\n",
    "        entry['bbox_abs'] = bbox_xyxy\n",
    "\n",
    "    gt_boxes = [ann[\"bbox_abs\"] for ann in gt_image_dict[\"annotations\"]]    \n",
    "\n",
    "    gt_classes = [ann[\"category_id\"] for ann in gt_image_dict[\"annotations\"]]\n",
    "\n",
    "    pred_boxes = [pred[\"bbox_abs\"] for pred in predictions_for_image]\n",
    "\n",
    "    pred_classes = [pred[\"category_id\"] for pred in predictions_for_image]\n",
    "    pred_score = [pred[\"score\"] for pred in predictions_for_image]\n",
    "\n",
    "    # Compute IoU between each ground truth box and predicted boxes\n",
    "    # Convert lists to tensors\n",
    "    tensor_gt_boxes = torch.tensor(gt_boxes)\n",
    "    tensor_pred_boxes = torch.tensor(pred_boxes)\n",
    "\n",
    "    # Create Boxes objects from tensors\n",
    "    boxes_gt = Boxes(tensor_gt_boxes)\n",
    "    boxes_pred = Boxes(tensor_pred_boxes)\n",
    "\n",
    "    iou_matrix = pairwise_iou(boxes_gt, boxes_pred)\n",
    "\n",
    "    above_threshold_indices = torch.nonzero(iou_matrix > upper_threshold, as_tuple=True)\n",
    "    below_threshold_indices = torch.nonzero((iou_matrix < upper_threshold) & (iou_matrix > lower_threshold), as_tuple=True)\n",
    "    above_0_indices = torch.nonzero(iou_matrix > 0, as_tuple=True)\n",
    "\n",
    "    boxesgt_above_threshold = boxes_gt.tensor[above_threshold_indices[0]]\n",
    "    boxespred_above_threshold = boxes_pred.tensor[above_threshold_indices[1]]\n",
    "    \n",
    "    boxesgt_below_threshold = boxes_gt.tensor[below_threshold_indices[0]]\n",
    "    boxespred_below_threshold = boxes_pred.tensor[below_threshold_indices[1]]\n",
    "\n",
    "    # Assuming gt_classes and pred_classes are dictionaries with box indices as keys\n",
    "    # Subselect classes for boxes above the threshold\n",
    "    gt_classes_above_threshold = {i: gt_classes[i] for i in above_threshold_indices[0]}\n",
    "    pred_classes_above_threshold = {i: pred_classes[i] for i in above_threshold_indices[1]}\n",
    "\n",
    "\n",
    "    # Subselect classes for boxes below the threshold\n",
    "    gt_classes_below_threshold = {i: gt_classes[i] for i in below_threshold_indices[0]}\n",
    "    pred_classes_below_threshold = {i: pred_classes[i] for i in below_threshold_indices[1]}\n",
    "\n",
    "    gt_classes_above_threshold_list = list(gt_classes_above_threshold.values())\n",
    "    pred_classes_above_threshold_list = list(pred_classes_above_threshold.values())\n",
    "\n",
    "    gt_classes_below_threshold_list = list(gt_classes_below_threshold.values())\n",
    "    pred_classes_below_threshold_list = list(pred_classes_below_threshold.values())\n",
    "\n",
    "    all_overlap_indices = torch.nonzero(iou_matrix > 0, as_tuple=True)\n",
    "\n",
    "    # Find the indices of false positive boxes by removing the indices of true positives\n",
    "    false_positive_indices = set(all_overlap_indices[1].tolist()) - set(above_threshold_indices[1].tolist())\n",
    "    false_positive_indices = list(false_positive_indices)\n",
    "\n",
    "    boxespred_false_positive = boxes_pred.tensor[false_positive_indices]\n",
    "    pred_classes_false_positive = {i: pred_classes[i] for i in false_positive_indices}\n",
    "    pred_classes_false_positive_list = list(pred_classes_false_positive.values())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    annotations_tp = []\n",
    "    annotations_class_fp = []\n",
    "    annotations_fp = []\n",
    "\n",
    "    true_positive.append(\n",
    "        {'image_id': image_id,\n",
    "        'filename': gt_image_dict[\"file_name\"],\n",
    "        'annotations': annotations_tp,\n",
    "        'type': 'True Positive'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    class_false_positive.append(\n",
    "        {'image_id': image_id,\n",
    "        'filename': gt_image_dict[\"file_name\"],\n",
    "        'annotations': annotations_class_fp,\n",
    "        'type': 'Class False Positive'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for i in range(len(gt_classes_above_threshold_list)):\n",
    "        if gt_classes_above_threshold_list[i] == pred_classes_above_threshold_list[i]:\n",
    "            annotations_tp.append(\n",
    "                {\n",
    "                    # 'image_id': image_id,\n",
    "                    # 'filename': gt_image_dict[\"file_name\"],\n",
    "                    'gt_class': gt_classes_above_threshold_list[i],\n",
    "                    'pred_class': pred_classes_above_threshold_list[i],\n",
    "                    'gt_box': boxesgt_above_threshold[i].tolist(),\n",
    "                    'pred_box': boxespred_above_threshold[i].tolist(),\n",
    "                    'pred_score': pred_score[i]\n",
    "                }\n",
    "            )\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            annotations_class_fp.append(\n",
    "                {\n",
    "                    # 'image_id': image_id,\n",
    "                    # 'filename': gt_image_dict[\"file_name\"],\n",
    "                    'gt_class': gt_classes_above_threshold_list[i],\n",
    "                    'pred_class': pred_classes_above_threshold_list[i],\n",
    "                    'gt_box': boxesgt_above_threshold[i].tolist(),\n",
    "                    'pred_box': boxespred_above_threshold[i].tolist(),\n",
    "                    'pred_score': pred_score[i]\n",
    "                    \n",
    "                }\n",
    "            )   \n",
    "        \n",
    "    # Update the false positive annotations\n",
    "    false_positive.append(\n",
    "        {\n",
    "            'image_id': image_id,\n",
    "            'filename': gt_image_dict[\"file_name\"],\n",
    "            'annotations': annotations_fp,\n",
    "            'type': 'False Positive'\n",
    "        }   \n",
    "    )\n",
    "\n",
    "    for i in range(len(boxespred_false_positive)):\n",
    "        annotations_fp.append(\n",
    "            {\n",
    "                'pred_class': pred_classes_false_positive_list[i],\n",
    "                'pred_box': boxespred_false_positive[i].tolist(),\n",
    "                'pred_score': pred_score[i],\n",
    "                'gt_class': 'none',\n",
    "            }\n",
    "        )\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Code for visualizing true positive, false positive and false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_predictions(class_id_to_label, output_dir, dictionary):\n",
    "  \"\"\"Highlights predictions on the image.\n",
    "\n",
    "  Args:\n",
    "    class_id_to_label: A dictionary mapping class IDs to labels and colors.\n",
    "    output_dir: The directory where the output images should be saved.\n",
    "    mismatch_info: A dictionary containing information about the false negative,\n",
    "      including the predicted bounding box, predicted class ID, ground truth class ID,\n",
    "      and image filename.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  for im in dictionary:\n",
    "    # Load the image if not already loaded\n",
    "    image = cv2.imread(im['filename'])\n",
    "\n",
    "    for ann in im['annotations']:\n",
    "      pred_box = ann['pred_box']\n",
    "      pred_class_id = ann['pred_class']\n",
    "      gt_class_id = ann['gt_class']\n",
    "      pred_score = ann['pred_score']\n",
    "      \n",
    "      # get label text and color\n",
    "      pred_label_text = class_id_to_label[pred_class_id][0]\n",
    "      gt_label_text = class_id_to_label[gt_class_id][0]\n",
    "      label_color = class_id_to_label[gt_class_id][1]  # Use ground truth class color\n",
    "\n",
    "      # Construct label text\n",
    "      label = f\"FN: GT-{gt_label_text}, PD-{pred_label_text} {pred_score:.2f}\"\n",
    "\n",
    "      pred_box = [int(coord) for coord in pred_box]\n",
    "\n",
    "\n",
    "      # Draw rectangle and put text on the image\n",
    "      cv2.rectangle(image, (pred_box[0], pred_box[1]), (pred_box[2], pred_box[3]), label_color, 2)\n",
    "      cv2.putText(image, label, (int(pred_box[0]), int(pred_box[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, label_color, 2)\n",
    "\n",
    "\n",
    "     # Display the image with highlighted false negatives in Jupyter Notebook\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image[:, :, ::-1])\n",
    "    plt.title(f\"{im['type']}, {im['image_id']}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{im['type']}_{im['image_id']}.png\"), image)\n",
    "\n",
    "draw_predictions(class_id_to_label, output_dir, class_false_positive)\n",
    "draw_predictions(class_id_to_label, output_dir, true_positive)\n",
    "draw_predictions(class_id_to_label, output_dir, false_positive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
