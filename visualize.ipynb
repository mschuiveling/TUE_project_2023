{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This code load the annotations, the output direction for the saved images and the name of the test set from which the images are visualized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "import json\n",
    "import os\n",
    "\n",
    "annotation_path = \"/mnt/d/TIL_Melanoma_train_database/cell_segmentation/open_source_dataset_tiles_final/til_melanoma.json\" # path to annotation file from 01_coco_creator_5fold\n",
    "with open(annotation_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    images = data['images']\n",
    "\n",
    "# Directory where the original annotation resides\n",
    "annotation_dir = os.path.dirname(annotation_path)\n",
    "\n",
    "# Predefined folder to save the visualized images\n",
    "output_dir = '/mnt/d/TIL_Melanoma_train_database/cell_segmentation/detectron2_inference'\n",
    "\n",
    "# Load the predictions\n",
    "predictions_file = '/home/mschuive/detectron2/output/inference/coco_instances_results.json'\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_set_name = 'temp_val_annotations_stratified_fold_4'\n",
    "test_set_name_json = test_set_name + '.json'\n",
    "if test_set_name in DatasetCatalog.list():\n",
    "    DatasetCatalog.remove(test_set_name)\n",
    "register_coco_instances(str(test_set_name), {}, os.path.join(annotation_dir, (test_set_name_json)), \"/mnt/d/TIL_Melanoma_train_database/cell_segmentation/tiles_1024_TIL_dataset_paper/redone/\")\n",
    "\n",
    "\n",
    "# Get dataset dictionaries\n",
    "dataset_dicts = DatasetCatalog.get(test_set_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Visualize random images from test set with ground truth, images are not saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset dictionaries\n",
    "dataset_dicts = DatasetCatalog.get(test_set_name)\n",
    "\n",
    "# Visualize some samples\n",
    "for d in random.sample(dataset_dicts, 5):  # Adjust the number to display as needed\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(test_set_name), scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    # plt.figure(figsize=(10,10))\n",
    "    # plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    # plt.title(d[\"file_name\"])\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Visualize predictions and save the images \n",
    "    NB update the predictions file localization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "with open(predictions_file, 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "from detectron2.structures import BoxMode, Instances\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_on_image(image, predictions_for_image):\n",
    "    \"\"\"\n",
    "    Visualizes predictions on the image.\n",
    "    \n",
    "    Args:\n",
    "    - image (np.ndarray): Image on which to visualize the predictions.\n",
    "    - predictions_for_image (list[dict]): List of predictions for the image.\n",
    "    \n",
    "    Returns:\n",
    "    - visualized_image (np.ndarray): Image with visualized predictions.\n",
    "    \"\"\"\n",
    "    # Convert the predictions in Detectron2's Instances format\n",
    "    instances = Instances(image_size=image.shape[:2])\n",
    "    bbox_list = [pred[\"bbox\"] for pred in predictions_for_image]\n",
    "    bbox_list_xyxy_abs = []\n",
    "    for bbox in bbox_list:\n",
    "        bbox = BoxMode.convert(bbox, from_mode=BoxMode.XYWH_ABS, to_mode=BoxMode.XYXY_ABS)\n",
    "        bbox_list_xyxy_abs.append(bbox)\n",
    "    instances.pred_boxes = bbox_list_xyxy_abs\n",
    "    cat_list_new = []\n",
    "    cat_list = [pred[\"category_id\"] for pred in predictions_for_image]\n",
    "    for cat in cat_list:\n",
    "        if cat == 1:\n",
    "            cat = 0\n",
    "        elif cat == 2:\n",
    "            cat = 1\n",
    "        else:\n",
    "            cat = 2\n",
    "        cat_list_new.append(cat)\n",
    "    cat_tensor = torch.tensor(cat_list_new)\n",
    "    instances.pred_classes = cat_tensor\n",
    "    instances.scores = [pred[\"score\"] for pred in predictions_for_image]\n",
    "    instances.pred_masks_rle = [pred[\"segmentation\"][\"counts\"]for pred in predictions_for_image]\n",
    "    \n",
    "    visualizer = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(test_set_name).set(thing_classes=['immune_cell', 'tumor', 'other']), scale=1.2)\n",
    "    vis = visualizer.draw_instance_predictions(predictions=instances)\n",
    "    return vis.get_image()[:, :, ::-1]\n",
    "\n",
    "# Get unique image_ids from the predictions\n",
    "image_ids = list(set([pred[\"image_id\"] for pred in predictions]))\n",
    "\n",
    "# For each unique image_id, visualize the predictions\n",
    "for image_id in image_ids:\n",
    "    # Get the image\n",
    "    image_dict = next(item for item in dataset_dicts if item[\"image_id\"] == image_id)\n",
    "    if image_dict is None:\n",
    "        print(f\"No item found for image_id {image_id}\")\n",
    "        continue  # Skip this iteration and continue with the next image_id\n",
    "    image = cv2.imread(image_dict[\"file_name\"])\n",
    "    \n",
    "    # Extract predictions for this image_id\n",
    "    predictions_for_image = [pred for pred in predictions if pred[\"image_id\"] == image_id]\n",
    "    \n",
    "    # Visualize the predictions on the image\n",
    "    visualized_image = visualize_predictions_on_image(image, predictions_for_image)\n",
    "    \n",
    "    # Save the image with highlighted false negatives to the output directory\n",
    "    output_path = os.path.join(output_dir, f\"predictions{image_id}.png\")\n",
    "    cv2.imwrite(output_path, visualized_image)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(visualized_image[:, :, ::-1])\n",
    "    plt.title(f\"Predictions for Image {image_id}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Code which creates dictionary's for visualizing false positive, false negative and class false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import pairwise_iou\n",
    "from detectron2.structures import Boxes, BoxMode\n",
    "import json\n",
    "import torch\n",
    "\n",
    "\n",
    "with open(predictions_file, 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "# Get unique image_ids from the predictions\n",
    "image_ids = list(set([pred[\"image_id\"] for pred in predictions]))\n",
    "\n",
    "\n",
    "class_id_to_label = {\n",
    "    0: [\"immune_cell\", (0, 0, 255)], # blue for immune cell \n",
    "    1: [\"tumor\", (255,0 ,0)] , # red for tumor\n",
    "    2: [\"other\", (0, 255, 0)], # green for other\n",
    "    'none' : [\"none\", (0, 0, 0)]\n",
    "}\n",
    "\n",
    "class_false_negative = []\n",
    "# IoU threshold to determine if a prediction matches a ground truth\n",
    "upper_threshold = 0.4  # Example value for upper threshold\n",
    "lower_threshold = 0.0  # Example value for lower threshold\n",
    "\n",
    "true_positive = []\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "class_false_positive = []\n",
    "\n",
    "# For each unique image_id, visualize the predictions\n",
    "for image_id in image_ids:\n",
    "\n",
    "    # Get the image\n",
    "    gt_image_dict = next(item for item in dataset_dicts if item[\"image_id\"] == image_id)\n",
    "    image = cv2.imread(gt_image_dict[\"file_name\"])\n",
    "\n",
    "    # Extract predictions for this image_id\n",
    "    predictions_for_image = [pred for pred in predictions if pred[\"image_id\"] == image_id]\n",
    "    for entry in predictions_for_image:\n",
    "        # Define a mapping dictionary\n",
    "        category_id_mapping = {1: 0, 2: 1, 3: 2}\n",
    "        entry['category_id'] = category_id_mapping[entry['category_id']]\n",
    "        bbox_xyxy = BoxMode.convert(entry['bbox'], from_mode=BoxMode.XYWH_ABS, to_mode=BoxMode.XYXY_ABS)\n",
    "        entry['bbox_abs'] = bbox_xyxy\n",
    "        # Extract the bbox_abs values and add their sum to total_sum\n",
    "\n",
    "  \n",
    "\n",
    "    # Extract ground truth bounding boxes and classes for this image_id\n",
    "    ground_truth_for_image = gt_image_dict[\"annotations\"]\n",
    "    for entry in ground_truth_for_image:\n",
    "        entry['category_id'] = entry['category_id']\n",
    "        bbox_xyxy = BoxMode.convert(entry['bbox'], from_mode=BoxMode.XYWH_ABS, to_mode=BoxMode.XYXY_ABS)\n",
    "        entry['bbox_abs'] = bbox_xyxy\n",
    "\n",
    "    gt_boxes = [ann[\"bbox_abs\"] for ann in gt_image_dict[\"annotations\"]]    \n",
    "\n",
    "    gt_classes = [ann[\"category_id\"] for ann in gt_image_dict[\"annotations\"]]\n",
    "\n",
    "    pred_boxes = [pred[\"bbox_abs\"] for pred in predictions_for_image]\n",
    "\n",
    "    pred_classes = [pred[\"category_id\"] for pred in predictions_for_image]\n",
    "    pred_score = [pred[\"score\"] for pred in predictions_for_image]\n",
    "\n",
    "    # Compute IoU between each ground truth box and predicted boxes\n",
    "    # Convert lists to tensors\n",
    "    tensor_gt_boxes = torch.tensor(gt_boxes)\n",
    "    tensor_pred_boxes = torch.tensor(pred_boxes)\n",
    "\n",
    "    # Create Boxes objects from tensors\n",
    "    boxes_gt = Boxes(tensor_gt_boxes)\n",
    "    boxes_pred = Boxes(tensor_pred_boxes)\n",
    "\n",
    "    iou_matrix = pairwise_iou(boxes_gt, boxes_pred)\n",
    "\n",
    "    above_threshold_indices = torch.nonzero(iou_matrix > upper_threshold, as_tuple=True)\n",
    "    below_threshold_indices = torch.nonzero((iou_matrix < upper_threshold) & (iou_matrix > lower_threshold), as_tuple=True)\n",
    "    above_0_indices = torch.nonzero(iou_matrix > 0, as_tuple=True)\n",
    "\n",
    "    boxesgt_above_threshold = boxes_gt.tensor[above_threshold_indices[0]]\n",
    "    boxespred_above_threshold = boxes_pred.tensor[above_threshold_indices[1]]\n",
    "    \n",
    "    boxesgt_below_threshold = boxes_gt.tensor[below_threshold_indices[0]]\n",
    "    boxespred_below_threshold = boxes_pred.tensor[below_threshold_indices[1]]\n",
    "\n",
    "    # Assuming gt_classes and pred_classes are dictionaries with box indices as keys\n",
    "    # Subselect classes for boxes above the threshold\n",
    "    gt_classes_above_threshold = {i: gt_classes[i] for i in above_threshold_indices[0]}\n",
    "    pred_classes_above_threshold = {i: pred_classes[i] for i in above_threshold_indices[1]}\n",
    "\n",
    "\n",
    "    # Subselect classes for boxes below the threshold\n",
    "    gt_classes_below_threshold = {i: gt_classes[i] for i in below_threshold_indices[0]}\n",
    "    pred_classes_below_threshold = {i: pred_classes[i] for i in below_threshold_indices[1]}\n",
    "\n",
    "    gt_classes_above_threshold_list = list(gt_classes_above_threshold.values())\n",
    "    pred_classes_above_threshold_list = list(pred_classes_above_threshold.values())\n",
    "\n",
    "    gt_classes_below_threshold_list = list(gt_classes_below_threshold.values())\n",
    "    pred_classes_below_threshold_list = list(pred_classes_below_threshold.values())\n",
    "\n",
    "    all_overlap_indices = torch.nonzero(iou_matrix > 0, as_tuple=True)\n",
    "\n",
    "    # Find the indices of false positive boxes by removing the indices of true positives\n",
    "    false_positive_indices = set(all_overlap_indices[1].tolist()) - set(above_threshold_indices[1].tolist())\n",
    "    false_positive_indices = list(false_positive_indices)\n",
    "\n",
    "    boxespred_false_positive = boxes_pred.tensor[false_positive_indices]\n",
    "    pred_classes_false_positive = {i: pred_classes[i] for i in false_positive_indices}\n",
    "    pred_classes_false_positive_list = list(pred_classes_false_positive.values())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    annotations_tp = []\n",
    "    annotations_class_fp = []\n",
    "    annotations_fp = []\n",
    "\n",
    "    true_positive.append(\n",
    "        {'image_id': image_id,\n",
    "        'filename': gt_image_dict[\"file_name\"],\n",
    "        'annotations': annotations_tp,\n",
    "        'type': 'True Positive'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    class_false_positive.append(\n",
    "        {'image_id': image_id,\n",
    "        'filename': gt_image_dict[\"file_name\"],\n",
    "        'annotations': annotations_class_fp,\n",
    "        'type': 'Class False Positive'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for i in range(len(gt_classes_above_threshold_list)):\n",
    "        if gt_classes_above_threshold_list[i] == pred_classes_above_threshold_list[i]:\n",
    "            annotations_tp.append(\n",
    "                {\n",
    "                    # 'image_id': image_id,\n",
    "                    # 'filename': gt_image_dict[\"file_name\"],\n",
    "                    'gt_class': gt_classes_above_threshold_list[i],\n",
    "                    'pred_class': pred_classes_above_threshold_list[i],\n",
    "                    'gt_box': boxesgt_above_threshold[i].tolist(),\n",
    "                    'pred_box': boxespred_above_threshold[i].tolist(),\n",
    "                    'pred_score': pred_score[i]\n",
    "                }\n",
    "            )\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            annotations_class_fp.append(\n",
    "                {\n",
    "                    # 'image_id': image_id,\n",
    "                    # 'filename': gt_image_dict[\"file_name\"],\n",
    "                    'gt_class': gt_classes_above_threshold_list[i],\n",
    "                    'pred_class': pred_classes_above_threshold_list[i],\n",
    "                    'gt_box': boxesgt_above_threshold[i].tolist(),\n",
    "                    'pred_box': boxespred_above_threshold[i].tolist(),\n",
    "                    'pred_score': pred_score[i]\n",
    "                    \n",
    "                }\n",
    "            )   \n",
    "        \n",
    "    # Update the false positive annotations\n",
    "    false_positive.append(\n",
    "        {\n",
    "            'image_id': image_id,\n",
    "            'filename': gt_image_dict[\"file_name\"],\n",
    "            'annotations': annotations_fp,\n",
    "            'type': 'False Positive'\n",
    "        }   \n",
    "    )\n",
    "\n",
    "    for i in range(len(boxespred_false_positive)):\n",
    "        annotations_fp.append(\n",
    "            {\n",
    "                'pred_class': pred_classes_false_positive_list[i],\n",
    "                'pred_box': boxespred_false_positive[i].tolist(),\n",
    "                'pred_score': pred_score[i],\n",
    "                'gt_class': 'none',\n",
    "            }\n",
    "        )\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Code for visualizing true positive, false positive and false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_predictions(class_id_to_label, output_dir, dictionary):\n",
    "  \"\"\"Highlights predictions on the image.\n",
    "\n",
    "  Args:\n",
    "    class_id_to_label: A dictionary mapping class IDs to labels and colors.\n",
    "    output_dir: The directory where the output images should be saved.\n",
    "    mismatch_info: A dictionary containing information about the false negative,\n",
    "      including the predicted bounding box, predicted class ID, ground truth class ID,\n",
    "      and image filename.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  for im in dictionary:\n",
    "    # Load the image if not already loaded\n",
    "    image = cv2.imread(im['filename'])\n",
    "\n",
    "    for ann in im['annotations']:\n",
    "      pred_box = ann['pred_box']\n",
    "      pred_class_id = ann['pred_class']\n",
    "      gt_class_id = ann['gt_class']\n",
    "      pred_score = ann['pred_score']\n",
    "      \n",
    "      # get label text and color\n",
    "      pred_label_text = class_id_to_label[pred_class_id][0]\n",
    "      gt_label_text = class_id_to_label[gt_class_id][0]\n",
    "      label_color = class_id_to_label[gt_class_id][1]  # Use ground truth class color\n",
    "\n",
    "      # Construct label text\n",
    "      label = f\"FN: GT-{gt_label_text}, PD-{pred_label_text} {pred_score:.2f}\"\n",
    "\n",
    "      pred_box = [int(coord) for coord in pred_box]\n",
    "\n",
    "\n",
    "      # Draw rectangle and put text on the image\n",
    "      cv2.rectangle(image, (pred_box[0], pred_box[1]), (pred_box[2], pred_box[3]), label_color, 2)\n",
    "      cv2.putText(image, label, (int(pred_box[0]), int(pred_box[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, label_color, 2)\n",
    "\n",
    "\n",
    "     # Display the image with highlighted false negatives in Jupyter Notebook\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image[:, :, ::-1])\n",
    "    plt.title(f\"{im['type']}, {im['image_id']}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{im['type']}_{im['image_id']}.png\"), image)\n",
    "\n",
    "draw_predictions(class_id_to_label, output_dir, class_false_positive)\n",
    "draw_predictions(class_id_to_label, output_dir, true_positive)\n",
    "draw_predictions(class_id_to_label, output_dir, false_positive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
